import os
import google.generativeai as genai
from dotenv import load_dotenv
from pathlib import Path
import json

# ==========================================
# ğŸ”§ å¼·åˆ¶è¼‰å…¥ .env
# ==========================================
current_file_path = Path(__file__).resolve()
backend_dir = current_file_path.parent.parent
env_path = backend_dir / '.env'
load_dotenv(dotenv_path=env_path)

api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    print("âŒ [LLM Service] åš´é‡éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GEMINI_API_KEYï¼Œè«‹æª¢æŸ¥ .env æª”æ¡ˆ")
else:
    genai.configure(api_key=api_key)

# ==========================================
# 1. å±¥æ­·åˆ†æåŠŸèƒ½ (ä¸Šå‚³ PDF/åœ–ç‰‡ç”¨)
# ==========================================
def generate_resume_advice(resume_text):
    """
    æ¥æ”¶å±¥æ­·æ–‡å­—ï¼Œå›å‚³çµæ§‹åŒ–çš„ JSON è³‡æ–™ (åŒ…å«è©•åˆ†ã€è·ç¼ºã€å°ˆæ¡ˆæ¨è–¦)ã€‚
    """
    print(f"[LLM Service] æ”¶åˆ°å±¥æ­·æ–‡å­—ï¼Œæ­£åœ¨é€²è¡Œ JSON çµæ§‹åŒ–åˆ†æ...")

    try:
        model = genai.GenerativeModel('gemini-2.0-flash')

        prompt = f"""
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è³‡æ·±æŠ€è¡“çµé ­èˆ‡è·æ¶¯æ•™ç·´ã€‚
        ä»¥ä¸‹æ˜¯æ±‚è·è€…çš„å±¥æ­·å…§å®¹ï¼ˆOCR è¾¨è­˜çµæœï¼‰ï¼š
        ---
        {resume_text}
        ---
        
        è«‹æ ¹æ“šä»¥ä¸Šå…§å®¹ï¼Œæä¾›å…¨é¢çš„è·æ¶¯åˆ†æã€‚
        
        âš ï¸ **éå¸¸é‡è¦ï¼šè«‹å‹™å¿…åªå›å‚³ç´” JSON æ ¼å¼å­—ä¸²ï¼Œä¸è¦ä½¿ç”¨ Markdown (å¦‚ ```json)ï¼Œä¹Ÿä¸è¦åŒ…å«å…¶ä»–é–‹å ´ç™½æˆ–çµå°¾æ–‡å­—ã€‚**
        
        JSON è³‡æ–™çµæ§‹å¿…é ˆåš´æ ¼éµå®ˆä»¥ä¸‹æ ¼å¼ï¼š
        {{
            "analysis": {{
                "score": (0-100çš„æ•´æ•¸),
                "strengths": ["å„ªé»1", "å„ªé»2", "å„ªé»3"],
                "weaknesses": ["å¼±é»1", "å¼±é»2"],
                "overall_comment": "ä¸€å¥è©±çš„æ•´é«”ç°¡çŸ­è©•èª"
            }},
            "job_recommendations": [
                {{ 
                    "title": "æ¨è–¦è·ç¨± (ä¾‹å¦‚ï¼šå¾Œç«¯å·¥ç¨‹å¸«)", 
                    "reason": "ç‚ºä»€éº¼é©åˆé€™å€‹è·ä½çš„ç†ç”±",
                    "missing_skills": ["ç¼ºå°‘çš„é—œéµæŠ€èƒ½1", "ç¼ºå°‘çš„é—œéµæŠ€èƒ½2"]
                }},
                {{ "title": "å¦ä¸€å€‹æ¨è–¦è·ç¨±", "reason": "...", "missing_skills": [] }}
            ],
            "project_recommendations": [
                {{
                    "name": "æ¨è–¦çš„ Side Project åç¨± (ä¾‹å¦‚ï¼šé›»å•†åº«å­˜ç³»çµ±)",
                    "difficulty": "æ˜“ / ä¸­ / é›£",
                    "tech_stack": "å»ºè­°ä½¿ç”¨çš„æŠ€è¡“ (ä¾‹å¦‚ï¼šReact + Firebase)",
                    "description": "é€™å€‹å°ˆæ¡ˆèƒ½å¦‚ä½•è£œå¼·å±¥æ­·å¼±é»çš„ç°¡çŸ­èªªæ˜"
                }},
                {{ "name": "å¦ä¸€å€‹å°ˆæ¡ˆ...", "difficulty": "...", "tech_stack": "...", "description": "..." }}
            ],
            "learning_path": [
                {{ "topic": "å»ºè­°å­¸ç¿’ä¸»é¡Œ", "resource": "æ¨è–¦è³‡æºé—œéµå­— (ä¾‹å¦‚ï¼šDocker å®˜æ–¹æ–‡ä»¶)", "priority": "é«˜/ä¸­/ä½", "url": "#" }}
            ]
        }}
        """

        response = model.generate_content(prompt)
        raw_text = response.text

        # ğŸ§¹ æ¸…ç†è³‡æ–™
        cleaned_text = raw_text.replace("```json", "").replace("```", "").strip()

        # ğŸ”„ å˜—è©¦è§£æ JSON
        try:
            advice_json = json.loads(cleaned_text)
            print("[LLM Service] å±¥æ­·åˆ†æ JSON è§£ææˆåŠŸï¼")
            return advice_json
        except json.JSONDecodeError as e:
            print(f"âš ï¸ [LLM Service] JSON è§£æå¤±æ•—: {e}")
            return {
                "analysis": {
                    "score": 0,
                    "strengths": [],
                    "weaknesses": [],
                    "overall_comment": "AI å›å‚³æ ¼å¼éŒ¯èª¤ï¼Œè«‹ç¨å¾Œé‡è©¦ã€‚"
                },
                "raw_text": raw_text
            }

    except Exception as e:
        print(f"[LLM Service] ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {"error": str(e)}


# ==========================================
# 2. å°ˆæ¡ˆæ¨è–¦åŠŸèƒ½ (Postman æ‰‹å‹•æŸ¥è©¢ç”¨)
# ==========================================
def generate_project_suggestions_from_skills(skills, interests):
    """
    æ ¹æ“šä½¿ç”¨è€…çš„æŠ€èƒ½ (List) å’Œèˆˆè¶£ (String) æ¨è–¦ Side Project
    """
    print(f"[LLM Service] æ”¶åˆ°æŠ€èƒ½æŸ¥è©¢: {skills}, èˆˆè¶£: {interests}")
    
    # è½‰æˆå­—ä¸²æ–¹ä¾¿å¡å…¥ Prompt
    skills_str = ", ".join(skills) if isinstance(skills, list) else str(skills)
    
    try:
        model = genai.GenerativeModel('gemini-2.0-flash')

        prompt = f"""
        ä½ æ˜¯ä¸€ä½æŠ€è¡“å°å¸«ã€‚ä½¿ç”¨è€…æƒ³åš Side Project ä¾†ç·´ç¿’æŠ€è¡“ã€‚
        
        ä½¿ç”¨è€…çš„æŠ€èƒ½æ¨¹ï¼š{skills_str}
        ä½¿ç”¨è€…çš„èˆˆè¶£é ˜åŸŸï¼š{interests}
        
        è«‹æ¨è–¦ 2 å€‹é©åˆä»–çš„ Side Projectã€‚
        
        âš ï¸ **è«‹å‹™å¿…åªå›å‚³ç´” JSON æ ¼å¼ï¼Œä¸è¦æœ‰ Markdownã€‚**
        æ ¼å¼å¦‚ä¸‹ï¼š
        {{
            "projects": [
                {{
                    "name": "å°ˆæ¡ˆåç¨±",
                    "difficulty": "æ˜“/ä¸­/é›£",
                    "tech_stack": "å»ºè­°æŠ€è¡“å †ç–Š",
                    "description": "ç°¡çŸ­èªªæ˜ç‚ºä½•é©åˆä»–"
                }},
                {{
                     "name": "å°ˆæ¡ˆåç¨±2",
                     "difficulty": "...",
                     "tech_stack": "...",
                     "description": "..."
                }}
            ]
        }}
        """
        
        response = model.generate_content(prompt)
        cleaned_text = response.text.replace("```json", "").replace("```", "").strip()
        
        try:
            return json.loads(cleaned_text)
        except json.JSONDecodeError:
            return {"projects": [], "error": "AI å›å‚³æ ¼å¼è§£æå¤±æ•—"}
            
    except Exception as e:
        print(f"AI ç”Ÿæˆå°ˆæ¡ˆå¤±æ•—: {e}")
        return {"projects": [], "error": str(e)}