import os
import google.generativeai as genai
from dotenv import load_dotenv
from pathlib import Path

# ==========================================
# ğŸ”§ å¼·åˆ¶è¼‰å…¥ .env (è§£æ±ºæ‰¾ä¸åˆ° Key çš„å•é¡Œ)
# ==========================================
# 1. æŠ“å‡ºç›®å‰æª”æ¡ˆçš„ä½ç½®
current_file_path = Path(__file__).resolve()

# 2. å¾€ä¸Šä¸€å±¤æ‰¾åˆ° backend è³‡æ–™å¤¾ (å› ç‚º .env åœ¨ backend åº•ä¸‹)
backend_dir = current_file_path.parent.parent

# 3. æŒ‡å®š .env çš„å®Œæ•´è·¯å¾‘
env_path = backend_dir / '.env'

# 4. è¼‰å…¥ï¼
load_dotenv(dotenv_path=env_path)

# 5. æª¢æŸ¥ Key æ˜¯å¦å­˜åœ¨
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    print("âŒ [LLM Service] åš´é‡éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GEMINI_API_KEYï¼Œè«‹æª¢æŸ¥ .env æª”æ¡ˆ")
else:
    # è¨­å®š API Key
    genai.configure(api_key=api_key)
# ==========================================

def generate_resume_advice(resume_text):
    """
    æ¥æ”¶å±¥æ­·æ–‡å­—ï¼Œä½¿ç”¨ Google Gemini é€²è¡Œæ·±åº¦åˆ†æä¸¦æä¾›å»ºè­°ã€‚
    """
    print(f"[LLM Service] æ”¶åˆ°æ–‡å­—ï¼Œé•·åº¦ï¼š{len(resume_text)} å­—")

    try:
        # ä½¿ç”¨ä½ å¸³è™Ÿæ”¯æ´çš„æœ€æ–°æ¨¡å‹ (è§£æ±º 404 éŒ¯èª¤)
        model = genai.GenerativeModel('gemini-2.0-flash')

        prompt = f"""
        ä½ æ˜¯ä¸€ä½è³‡æ·±çš„è·æ¶¯é¡§å•èˆ‡å±¥æ­·å„ªåŒ–å°ˆå®¶ã€‚è«‹é‡å°ä½¿ç”¨è€…çš„å±¥æ­·å…§å®¹é€²è¡Œåˆ†æã€‚
        ä½ çš„å›æ‡‰å¿…é ˆåŒ…å«ä»¥ä¸‹ä¸‰å€‹éƒ¨åˆ†ï¼Œä¸¦ä½¿ç”¨ Markdown æ ¼å¼ï¼š
        
        1. **ã€å„ªé»åˆ†æã€‘**ï¼šæ‰¾å‡ºé€™ä»½å±¥æ­·åšå¾—å¥½çš„åœ°æ–¹ (2-3 é»)ã€‚
        2. **ã€é—œéµå•é¡Œã€‘**ï¼šæŒ‡å‡ºå±¥æ­·ä¸­è‡´å‘½çš„ç¼ºé»æˆ–ä¸å¤ å¥½çš„åœ°æ–¹ (ä¾‹å¦‚ï¼šç¼ºä¹é‡åŒ–æ•¸æ“šã€æ’ç‰ˆæ··äº‚ã€æŠ€èƒ½æè¿°æ¨¡ç³Š)ã€‚
        3. **ã€å…·é«”ä¿®æ”¹å»ºè­°ã€‘**ï¼šæä¾› 3-5 æ¢å…·é«”çš„ä¿®æ”¹å»ºè­°ï¼Œå‘Šè¨´ä½¿ç”¨è€…è©²æ€éº¼æ”¹å¯«æœƒæ›´å¸å¼• HRã€‚
        
        èªæ°£è¦å°ˆæ¥­ã€é¼“å‹µäººå¿ƒä½†é‡é‡è¦‹è¡€ã€‚
        
        ä»¥ä¸‹æ˜¯ä½¿ç”¨è€…çš„å±¥æ­·å…§å®¹ï¼š
        {resume_text}
        """

        response = model.generate_content(prompt)

        advice = response.text
        print("[LLM Service] å»ºè­°ç”Ÿæˆå®Œæˆï¼")
        return advice

    except Exception as e:
        print(f"[LLM Service] ç™¼ç”ŸéŒ¯èª¤: {e}")
        return f"AI åˆ†æå¤±æ•—: {str(e)}"